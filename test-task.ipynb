{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "496b3711-787d-476c-b901-56ad5bd9d54a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64bb865d-1d4b-4522-abce-b1505844c686",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPS = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44fdf93b-30b9-4c3e-bf4c-f251471b8f21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2abc2fee-92cf-41e5-bcd6-f842bfc3b18c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    assert len(X.shape) == 4, \"X must be with shape [batch, h, w, c]\"\n",
    "    \n",
    "    X_pad = np.pad(X, (\n",
    "        (0, 0), \n",
    "        (pad, pad), \n",
    "        (pad, pad), \n",
    "        (0, 0)\n",
    "    ), mode=\"constant\", constant_values=(0, 0))\n",
    "\n",
    "    return X_pad\n",
    "\n",
    "\n",
    "class Conv2D:\n",
    "    def __init__(self, prev_channels, next_channels, kernel=3, stride=1, pad=0, dtype=float):\n",
    "        self._cache = None\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        self.dtype = dtype \n",
    "        \n",
    "        self.kernel = np.random.randn(kernel, kernel, prev_channels, next_channels).astype(self.dtype)\n",
    "        self.b = np.zeros(next_channels, dtype=self.dtype)\n",
    "    \n",
    "    def forward(self, A_prev):\n",
    "        # (m, n_H_prev, n_W_prev, n_C_prev) -> (m, n_H, n_W, n_C) by (k, k, n_C_prev, n_C)\n",
    "\n",
    "        m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
    "        k, k, n_C_prev, n_C = self.kernel.shape\n",
    "\n",
    "        n_H = (n_H_prev + 2*self.pad - k) // self.stride + 1\n",
    "        n_W = (n_W_prev + 2*self.pad - k) // self.stride + 1\n",
    "\n",
    "        output = np.zeros((m, n_H, n_W, n_C), dtype=A_prev.dtype)\n",
    "        A_prev_pad = zero_pad(A_prev, pad=self.pad)\n",
    "        \n",
    "        for i in range(m):\n",
    "            a_prev_pad = A_prev_pad[i]\n",
    "\n",
    "            for h in range(n_H):\n",
    "                h_start = h * self.stride \n",
    "                h_end = h_start + k\n",
    "\n",
    "                for w in range(n_W):\n",
    "                    w_start = w * self.stride\n",
    "                    w_end = w_start + k\n",
    "\n",
    "                    for c in range(n_C):\n",
    "                        a_slice = a_prev_pad[h_start:h_end, w_start:w_end, :]\n",
    "                        current_kernel = self.kernel[:, :, :, c]\n",
    "                        current_bias = self.b[c]\n",
    "                       \n",
    "                        output[i, h, w, c] = np.sum(a_slice * current_kernel) + current_bias\n",
    "        \n",
    "        self.cache = A_prev\n",
    "        return output\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        A_prev = self.cache\n",
    "        \n",
    "        m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
    "        k, k, n_C_prev, n_C = self.kernel.shape\n",
    "        m, n_H, n_W, n_C = dZ.shape \n",
    "        \n",
    "        dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev), dtype=self.dtype)\n",
    "        dW = np.zeros((k, k, n_C_prev, n_C), dtype=self.dtype)\n",
    "        db = np.zeros(n_C, dtype=self.dtype)\n",
    "        \n",
    "        A_prev_pad = zero_pad(A_prev, self.pad)\n",
    "        dA_prev_pad = zero_pad(dA_prev, self.pad)\n",
    "        \n",
    "        for i in range(m):\n",
    "            a_prev_pad = A_prev_pad[i]\n",
    "            da_prev_pad = dA_prev_pad[i]\n",
    "            \n",
    "            for h in range(n_H):\n",
    "                h_start = h * self.stride \n",
    "                h_end = h_start + k\n",
    "                \n",
    "                for w in range(n_W):\n",
    "                    w_start = w * self.stride\n",
    "                    w_end = w_start + k\n",
    "                    \n",
    "                    for c in range(n_C):\n",
    "                        a_slice = a_prev_pad[h_start:h_end, w_start:w_end, :]\n",
    "                        \n",
    "                        da_prev_pad[h_start:h_end, w_start:w_end, :] += self.kernel[:, :, :, c] * dZ[i, h, w, c]\n",
    "                        dW[:, :, :, c] += a_slice * dZ[i, h, w, c]\n",
    "                        db[c] += dZ[i, h, w, c]\n",
    "            if self.pad == 0:\n",
    "                dA_prev[i, :, :, :] = da_prev_pad[:, :, :]\n",
    "            else:\n",
    "                dA_prev[i, :, :, :] = da_prev_pad[self.pad:-self.pad, self.pad:-self.pad, :]\n",
    "            \n",
    "        assert dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "            \n",
    "        return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04ae3a52-e9b3-40d9-9684-8f698708d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(X, stride=2, pad=0):\n",
    "    assert len(X.shape) == 4, \"X should be with shape [batch, h, w, c]\"\n",
    "    \n",
    "    m, n_H_prev, n_W_prev, c = X.shape\n",
    "    \n",
    "    n_H = stride * (n_H_prev - 1) + 1\n",
    "    n_W = stride * (n_W_prev - 1) + 1\n",
    "    \n",
    "    upsampled = np.zeros((m, n_H, n_W, c), dtype=X.dtype)\n",
    "    \n",
    "    for h in range(n_H_prev):\n",
    "        for w in range(n_W_prev):\n",
    "            upsampled[:, h*stride, w*stride, :] = X[:, h, w, :]\n",
    "    \n",
    "    upsampled_pad = zero_pad(upsampled, pad=pad)\n",
    "    \n",
    "    return upsampled_pad\n",
    "\n",
    "\n",
    "def downsample(X, stride, pad):\n",
    "    if pad == 0:\n",
    "        pad = None \n",
    "\n",
    "    res = X[:, pad:-pad:stride, pad:-pad:stride, :]\n",
    "    return res\n",
    "\n",
    "\n",
    "class Conv2DTranspose:\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=0):\n",
    "        self.cache = None \n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "        \n",
    "        self.conv = Conv2D(in_channels, out_channels, kernel=kernel_size, stride=1, pad=0)\n",
    "        \n",
    "    def forward(self, A_prev):\n",
    "        m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape \n",
    "        k, k, n_C_prev, n_C = self.kernel.shape\n",
    "        \n",
    "        n_H = self.stride * (n_H_prev - 1) + k - 2 * self.padding\n",
    "        n_W = self.stride * (n_W_prev - 1) + k - 2 * self.padding\n",
    "        \n",
    "        implicit_padding = k - self.padding - 1\n",
    "        assert implicit_padding >= 0\n",
    "        \n",
    "        A_prev_upsampled = upsample(A_prev, stride=self.stride, pad=implicit_padding)\n",
    "        out = self.conv.forward(A_prev_upsampled)\n",
    "        \n",
    "        assert out.shape == (m, n_H, n_W, n_C)\n",
    "        \n",
    "        self.cache = A_prev\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        A_prev = self.cache \n",
    "        m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
    "        k, k, n_C_prev, n_C = self.kernel.shape\n",
    "        m, n_H, n_W, n_C = dZ.shape\n",
    "        \n",
    "        dA_upsampled, dW, db = self.conv.backward(dZ)\n",
    "        \n",
    "        implicit_padding = k - self.padding - 1\n",
    "        dA = downsample(dA_upsampled, self.stride, pad=implicit_padding)\n",
    "        \n",
    "        return dA, dW, db\n",
    "    \n",
    "    @property \n",
    "    def kernel(self):\n",
    "        return self.conv.kernel\n",
    "    \n",
    "    @kernel.setter\n",
    "    def kernel(self, weights):\n",
    "        self.conv.kernel = weights\n",
    "        \n",
    "    @property \n",
    "    def b(self):\n",
    "        return self.conv.b\n",
    "    \n",
    "    @kernel.setter\n",
    "    def b(self, biases):\n",
    "        self.conv.b = biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64ae86a-626c-4e8c-8aca-f9f0721fc796",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e258e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Test zero_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da845423-11ef-46e9-aabf-9684b311e9a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 40, 40, 3) (30, 42, 42, 3)\n",
      "True True True True\n"
     ]
    }
   ],
   "source": [
    "m = 30\n",
    "h = 40\n",
    "w = 40\n",
    "c = 3\n",
    "pad = 1\n",
    "\n",
    "X_batch = np.random.rand(m, h, w, c)\n",
    "shape1 = X_batch.shape\n",
    "X_pad = zero_pad(X_batch, pad=pad)\n",
    "shape2 = X_pad.shape\n",
    "\n",
    "print(shape1, shape2)\n",
    "print(\n",
    "    shape1[0] == shape2[0], \n",
    "    shape1[1]+pad*2 == shape2[1], \n",
    "    shape1[2]+2*pad == shape2[2], \n",
    "    shape1[3] == shape2[3]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65249e85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b = np.random.rand(1, 1, 1)\n",
    "b = 1\n",
    "b = np.array(b)\n",
    "b.shape == (1, 1, 1) or b.shape == ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7669ae0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Test window_mmult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9df1761c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input_slice = np.array([\n",
    "#     [1, 0, 0],\n",
    "#     [1, 0, 0],\n",
    "#     [1, 0, 0]\n",
    "# ], dtype=np.float32)\n",
    "\n",
    "# kernel = np.array([\n",
    "#     [-1, 0, 1],\n",
    "#     [-1, 0, 1],\n",
    "#     [-1, 0, 1]\n",
    "# ], dtype=np.float32)\n",
    "\n",
    "# # b = 1\n",
    "# b = np.array([[[1]]], dtype=np.float32)\n",
    "\n",
    "# kernel = kernel[..., np.newaxis]\n",
    "# input_slice = input_slice[..., np.newaxis]\n",
    "\n",
    "# print(kernel.shape)\n",
    "# print(input_slice.shape)\n",
    "# print(b.shape)\n",
    "\n",
    "# conv2d = Conv2D(1, 1)\n",
    "\n",
    "# z = conv2d._window_mult(input_slice, kernel, b)\n",
    "# print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716c99ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Conv2D forward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6361df3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 33, 33, 16)\n"
     ]
    }
   ],
   "source": [
    "m = 16\n",
    "n_H_prev = 33\n",
    "n_W_prev = 33\n",
    "n_C_prev = 8\n",
    "n_C = 16\n",
    "\n",
    "kernel = 3\n",
    "pad = 1\n",
    "stride = 1\n",
    "\n",
    "\n",
    "X_batch = np.random.rand(m, n_H_prev, n_W_prev, n_C_prev)\n",
    "conv2d = Conv2D(n_C_prev, n_C, kernel=kernel, pad=pad, stride=stride)\n",
    "out = conv2d.forward(X_batch)\n",
    "print(out.shape)\n",
    "\n",
    "del m \n",
    "del n_H_prev\n",
    "del n_W_prev\n",
    "del n_C_prev\n",
    "del n_C\n",
    "del kernel\n",
    "del pad \n",
    "del stride"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c95c9f-5f4f-49c5-8b93-a4b9d7279ad7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Comparing forward with torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4628ee0-0aed-4e12-9cbc-0a59a792a101",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5816505494095304e-30\n",
      "\u001b[92m\u001b[1mOK\n"
     ]
    }
   ],
   "source": [
    "def compare_conv(\n",
    "            m, \n",
    "            n_H_prev, \n",
    "            n_W_prev, \n",
    "            n_C_prev, \n",
    "            n_C, \n",
    "            kernel,\n",
    "            pad, \n",
    "            stride\n",
    "        ):\n",
    "    \n",
    "    input_data = np.random.rand(m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    \n",
    "    # my realization \n",
    "    my_conv = Conv2D(n_C_prev, n_C, kernel=kernel, stride=stride, pad=pad)\n",
    "    my_out = my_conv.forward(input_data)\n",
    "    \n",
    "    # torch_realizatoin \n",
    "    torch_input = torch.permute(torch.from_numpy(input_data), [0, 3, 1, 2]) # (m, n_C_prev, n_H_prev, n_W_prev)\n",
    "    torch_weights = torch.permute(torch.from_numpy(my_conv.kernel), [3, 2, 0, 1]) # [k, k, channels, filters] -> [filters, channels, k, k]\n",
    "    torch_biases = torch.from_numpy(my_conv.b)\n",
    "    torch_out_ = F.conv2d(torch_input, torch_weights, bias=torch_biases, padding=pad, stride=stride)\n",
    "    \n",
    "    torch_out = torch.permute(torch_out_, [0, 2, 3, 1]).numpy() \n",
    "    \n",
    "    mse = np.power(my_out - torch_out, 2).mean()\n",
    "    \n",
    "    return mse\n",
    "\n",
    "res = compare_conv(\n",
    "    m = 16,\n",
    "    n_H_prev = 32,\n",
    "    n_W_prev = 32,\n",
    "    n_C_prev = 8,\n",
    "    n_C = 16,\n",
    "\n",
    "    kernel = 3,\n",
    "    pad = 1,\n",
    "    stride = 1,\n",
    ")\n",
    "print(res)\n",
    "\n",
    "if res < EPS:\n",
    "    print(Color.GREEN + Color.BOLD + \"OK\")\n",
    "else:\n",
    "    print(Color.RED + Color.BOLD + \"Error\")\n",
    "    \n",
    "del res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dcb239-de64-4fab-9475-e95e4a62d0e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Conv2d backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13ced207-1c2e-4687-b408-7af8899dc328",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 32, 32, 8)\n",
      "(3, 3, 8, 16)\n",
      "(16,)\n"
     ]
    }
   ],
   "source": [
    "kernel = 3\n",
    "pad = 1\n",
    "stride = 1\n",
    "\n",
    "m = 16\n",
    "n_H_prev = 32\n",
    "n_W_prev = 32\n",
    "n_C_prev = 8\n",
    "n_C = 16\n",
    "\n",
    "n_H = (n_H_prev + 2*pad - kernel) // stride + 1\n",
    "n_W = (n_W_prev + 2*pad - kernel) // stride + 1\n",
    "\n",
    "input_data = np.random.rand(m, n_H_prev, n_W_prev, n_C_prev)\n",
    "dZ = np.random.rand(m, n_H, n_W, n_C)\n",
    "\n",
    "my_conv = Conv2D(n_C_prev, n_C, kernel=kernel, stride=stride, pad=pad)\n",
    "conv_out = my_conv.forward(input_data)\n",
    "\n",
    "dA, dW, db = my_conv.backward(dZ)\n",
    "print(dA.shape)\n",
    "print(dW.shape)\n",
    "print(db.shape)\n",
    "\n",
    "\n",
    "del kernel\n",
    "del pad\n",
    "del stride\n",
    "\n",
    "del m\n",
    "del n_H_prev\n",
    "del n_W_prev\n",
    "del n_C_prev\n",
    "del n_C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8064d5-1118-43e7-88e7-e0bf57ca65b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Comparsion backward with torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b04000f-41f0-4dc1-9a00-b0254a2d1225",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_conv_back(\n",
    "            kernel,\n",
    "            pad,\n",
    "            stride,\n",
    "            m,\n",
    "            n_H_prev,\n",
    "            n_W_prev,\n",
    "            n_C_prev,\n",
    "            n_C,\n",
    "        ):\n",
    "    n_H = (n_H_prev + 2*pad - kernel) // stride + 1\n",
    "    n_W = (n_W_prev + 2*pad - kernel) // stride + 1\n",
    "    \n",
    "    input_data = np.random.rand(m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    dZ = np.random.rand(m, n_H, n_W, n_C)\n",
    "    \n",
    "    weights = np.random.randn(kernel, kernel, n_C_prev, n_C)\n",
    "    biases = np.zeros(n_C, dtype=float)\n",
    "    \n",
    "    # my realization \n",
    "    my_conv = Conv2D(n_C_prev, n_C, kernel=kernel, stride=stride, pad=pad)\n",
    "    my_conv.kernel = weights.copy()\n",
    "    my_conv.b = biases.copy()\n",
    "    \n",
    "    conv_out = my_conv.forward(input_data)\n",
    "\n",
    "    dA, dW, db = my_conv.backward(dZ)\n",
    "    \n",
    "    # torch realization\n",
    "    torch_input = torch.permute(torch.from_numpy(input_data), [0, 3, 1, 2])\n",
    "    torch_dZ = torch.permute(torch.from_numpy(dZ), [0, 3, 1, 2])\n",
    "    torch_weights = torch.permute(torch.from_numpy(weights.copy()), [3, 2, 0, 1])\n",
    "    torch_biases = torch.from_numpy(biases.copy())\n",
    "    \n",
    "    torch_input.requires_grad = True\n",
    "    torch_weights.requires_grad = True\n",
    "    torch_biases.requires_grad = True\n",
    "    torch_dZ.requires_grad = False\n",
    "    \n",
    "    torch_out = F.conv2d(torch_input, torch_weights, bias=torch_biases, padding=pad, stride=stride)\n",
    "    # loss = torch.sum(torch_out * torch_dZ)\n",
    "    \n",
    "    # loss.backward()\n",
    "    \n",
    "    torch_out.backward(gradient=torch_dZ)\n",
    "    \n",
    "    dA_torch = torch_input.grad\n",
    "    dW_torch = torch_weights.grad\n",
    "    db_torch = torch_biases.grad\n",
    "    \n",
    "    dA_torch = torch.permute(dA_torch, [0, 2, 3, 1]).numpy() # [m, channels, h, w] -> [m, h, w, channels]\n",
    "    dW_torch = torch.permute(dW_torch, [2, 3, 1, 0]).numpy() # [filters, channels, k, k] -> [k, k, channels, filters] \n",
    "    db_torch = db_torch.numpy()\n",
    "    \n",
    "    assert dA.shape == dA_torch.shape and dW.shape == dW_torch.shape and db.shape == db_torch.shape\n",
    "    \n",
    "    mse = lambda a, b: np.power(a - b, 2).mean()\n",
    "    mse_dA = mse(dA, dA_torch)\n",
    "    mse_dW = mse(dW, dW_torch)\n",
    "    mse_db = mse(db, db_torch)\n",
    "    \n",
    "    return mse_dA, mse_dW, mse_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbf7bd18-cdb1-4402-8cb4-2f0dc7cf1594",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1mOK\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "mse_dA, mse_dW, mse_db = compare_conv_back(\n",
    "    kernel = 3,\n",
    "    pad = 1,\n",
    "    stride = 1,\n",
    "\n",
    "    m = 16,\n",
    "    n_H_prev = 32,\n",
    "    n_W_prev = 32,\n",
    "    n_C_prev = 8,\n",
    "    n_C = 16\n",
    ")\n",
    "\n",
    "if mse_dA < EPS and mse_dW < EPS and mse_db < EPS:\n",
    "    print(Color.GREEN + Color.BOLD + \"OK\")\n",
    "else:\n",
    "    print(Color.RED + Color.BOLD + \"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e84dfb-97f5-4321-9ab6-a65798a56745",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Conv2D Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f9e666f-3e54-418a-84ad-6bc15bce9b6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   4   0]\n",
      " [ 18 127  57]\n",
      " [  0   8   0]]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([\n",
    "    [2, 5],\n",
    "    [4, 13]\n",
    "])\n",
    "kernel = np.array([\n",
    "    [3, 1, 2],\n",
    "    [2, 0, 0],\n",
    "    [5, 4, 7]\n",
    "])\n",
    "\n",
    "batch = arr[np.newaxis, ..., np.newaxis]\n",
    "weights = kernel[..., np.newaxis, np.newaxis]\n",
    "\n",
    "convt = Conv2DTranspose(1, 1, kernel_size=3, stride=2, padding=1)\n",
    "convt.kernel = weights\n",
    "\n",
    "out = convt.forward(batch)\n",
    "print(out.squeeze())\n",
    "\n",
    "\n",
    "del convt\n",
    "del out \n",
    "del weights \n",
    "del batch\n",
    "del kernel \n",
    "del arr\n",
    "\n",
    " # [  0   4   0]\n",
    " # [ 18 127  57]\n",
    " # [  0   8   0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bd766b-6491-4c2c-94e1-a8a0fb875c3e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Conv2D Comparsion with Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c27de602-5f7b-4e65-b92b-551fab0567d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05124965867449682\n"
     ]
    }
   ],
   "source": [
    "def compare_convt(\n",
    "            m,\n",
    "            n_H_prev,\n",
    "            n_W_prev,\n",
    "            n_C_prev,\n",
    "            n_C,\n",
    "            kernel,\n",
    "            pad,\n",
    "            stride\n",
    "        ):\n",
    "    input_data = np.random.rand(m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    weights = np.random.rand(kernel, kernel, n_C_prev, n_C)\n",
    "    biases = np.zeros(n_C)\n",
    "    \n",
    "    # my realizatoin \n",
    "    my_convt = Conv2DTranspose(n_C_prev, n_C, kernel_size=kernel, stride=stride, padding=pad)\n",
    "    my_convt.kernel = weights\n",
    "    my_convt.b = biases\n",
    "    \n",
    "    my_out = my_convt.forward(input_data)\n",
    "    \n",
    "    # torch realization \n",
    "    torch_input = torch.permute(torch.from_numpy(input_data), [0, 3, 1, 2]) # (m, n_C_prev, n_H_prev, n_W_prev)\n",
    "    torch_weights = torch.permute(torch.from_numpy(weights), [2, 3, 0, 1]) # [k, k, channels, filters] -> [channels, filters, k, k]\n",
    "    torch_biases = torch.from_numpy(biases)\n",
    "    torch_out_ = F.conv_transpose2d(torch_input, torch_weights, bias=torch_biases, padding=pad, stride=stride)\n",
    "    \n",
    "    torch_out = torch.permute(torch_out_, [0, 2, 3, 1]).numpy() \n",
    "    \n",
    "    mse = np.power(my_out - torch_out, 2).mean()\n",
    "    return mse\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "res = compare_convt(\n",
    "    m = 1,\n",
    "    n_H_prev = 2,\n",
    "    n_W_prev = 2,\n",
    "    n_C_prev = 1,\n",
    "    n_C = 1,\n",
    "    kernel = 3,\n",
    "    pad = 0,\n",
    "    stride = 1\n",
    ")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384a6cc9-c02d-42e5-8e9d-6788eccdfd95",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Conv2D Transpose backward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b38bb1ad-dfe1-4ac2-8d1b-d2a93742e102",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 16, 16, 32)\n",
      "(3, 3, 32, 8)\n",
      "(16,)\n"
     ]
    }
   ],
   "source": [
    "kernel = 3\n",
    "pad = 1\n",
    "stride = 1\n",
    "\n",
    "m = 4\n",
    "n_H_prev = 16\n",
    "n_W_prev = 16\n",
    "n_C_prev = 32\n",
    "n_C = 8\n",
    "\n",
    "n_H = stride * (n_H_prev - 1) + kernel - 2 * pad\n",
    "n_W = stride * (n_W_prev - 1) + kernel - 2 * pad\n",
    "\n",
    "input_data = np.random.rand(m, n_H_prev, n_W_prev, n_C_prev)\n",
    "dZ = np.random.rand(m, n_H, n_W, n_C)\n",
    "\n",
    "convt = Conv2DTranspose(n_C_prev, n_C, kernel_size=kernel, stride=stride, padding=pad)\n",
    "fout = convt.forward(input_data)\n",
    "dA, dW, dz = convt.backward(dZ)\n",
    "\n",
    "print(dA.shape)\n",
    "print(dW.shape)\n",
    "print(db.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037df71b-aa28-442c-92b9-b1086b470e03",
   "metadata": {},
   "source": [
    "## Comparsion Conv2D transpose with torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29f7b97e-2070-4249-8a30-9f42db172a26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.80346068783682\n",
      "37.201668270385746\n",
      "4.13994203059987e-28\n"
     ]
    }
   ],
   "source": [
    "def compare_convt_back(\n",
    "            kernel,\n",
    "            pad,\n",
    "            stride,\n",
    "            m,\n",
    "            n_H_prev,\n",
    "            n_W_prev,\n",
    "            n_C_prev,\n",
    "            n_C,\n",
    "        ):\n",
    "    n_H = stride * (n_H_prev - 1) + kernel - 2 * pad\n",
    "    n_W = stride * (n_W_prev - 1) + kernel - 2 * pad\n",
    "    \n",
    "    input_data = np.random.rand(m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    dZ = np.random.randn(m, n_H, n_W, n_C)\n",
    "    \n",
    "    weights = np.random.randn(kernel, kernel, n_C_prev, n_C)\n",
    "    biases = np.random.rand(n_C)\n",
    "    \n",
    "    # my realization \n",
    "    convt = Conv2DTranspose(n_C_prev, n_C, kernel_size=kernel, stride=stride, padding=pad)\n",
    "    convt.kernel = weights.copy()\n",
    "    convt.biases = biases.copy()\n",
    "    \n",
    "    my_out = convt.forward(input_data)\n",
    "    dA, dW, db = convt.backward(dZ)\n",
    "    \n",
    "    # torch realization \n",
    "    torch_input = torch.permute(torch.from_numpy(input_data), [0, 3, 1, 2]) # (batch, h, w, in_channels) -> (batch, in_channels, h, w)\n",
    "    torch_dZ = torch.permute(torch.from_numpy(dZ), [0, 3, 1, 2]) # (batch, h, w, out_channels) -> (batch, out_channels, h, w)\n",
    "    torch_weights = torch.permute(torch.from_numpy(weights.copy()), [2, 3, 0, 1]) # (k, k, in_channels, out_channels) -> (in_channels, out_channels, k, k)\n",
    "    torch_biases = torch.from_numpy(biases.copy())\n",
    "    \n",
    "    torch_input.requires_grad = True\n",
    "    torch_weights.requires_grad = True\n",
    "    torch_biases.requires_grad = True\n",
    "    torch_dZ.requires_grad = False\n",
    "    \n",
    "    torch_out = F.conv_transpose2d(torch_input, torch_weights, bias=torch_biases, padding=pad, stride=stride)\n",
    "    torch_out.backward(gradient=torch_dZ)\n",
    "    \n",
    "    dA_torch = torch_input.grad\n",
    "    dW_torch = torch_weights.grad\n",
    "    db_torch = torch_biases.grad\n",
    "    \n",
    "    dA_torch = torch.permute(dA_torch, [0, 2, 3, 1]).numpy() # (batch, in_channels, h, w) -> (batch, h, w, in_channels)\n",
    "    dW_torch = torch.permute(dW_torch, [2, 3, 0, 1]).numpy() # (in_channels, out_channels, k, k) -> (k, k, in_channels, out_channels) \n",
    "    db_torch = db_torch.numpy()\n",
    "    \n",
    "    assert dA.shape == dA_torch.shape and dW.shape == dW_torch.shape and db.shape == db_torch.shape\n",
    "    \n",
    "    mse = lambda a, b: np.power(a - b, 2).mean()\n",
    "    mse_dA = mse(dA, dA_torch)\n",
    "    mse_dW = mse(dW, dW_torch)\n",
    "    mse_db = mse(db, db_torch)\n",
    "    \n",
    "    return mse_dA, mse_dW, mse_db\n",
    "    \n",
    "    \n",
    "\n",
    "mse_dA, mse_dW, mse_db = compare_convt_back(\n",
    "    m = 1,\n",
    "    n_H_prev = 16,\n",
    "    n_W_prev = 16,\n",
    "    n_C_prev = 7,\n",
    "    n_C = 5,\n",
    "    kernel = 3,\n",
    "    pad = 1,\n",
    "    stride = 2\n",
    ")\n",
    "\n",
    "print(mse_dA)\n",
    "print(mse_dW)\n",
    "print(mse_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca4d39d-4060-47d5-a5a4-0fd64e46d580",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd7aebf-f8b4-42e9-95cd-95d6f564b4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
